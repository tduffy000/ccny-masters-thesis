sr: 16000
raw_data:
  path: /home/thomas/Dir/ccny/ccny-masters-thesis/raw-data
  datasets:
    LibriSpeech:
      - dev-clean
feature_data:
  path: /home/thomas/Dir/ccny/ccny-masters-thesis/feature-data
  buffer_flush_size: 500 # for number of TFExamples in a TFRecord file
  test_ratio: 0.5
features:
  type: melspectrogram
  window_length: 1.0 # seconds
  overlap_percent: 0.5 # out of 1.0
  frame_length: 0.025 # seconds
  hop_length: 0.01 # seconds
  n_fft: 512
  n_mels: 128
  use_preemphasis: False
  trim_silence: True
  trim_top_db: 30
  # normalization: max
train:
  epochs: 10
  batch_size: 16
  input_dimensions: 2 # 2 for Conv1D and 3 for Conv2D
  network:
    loss: sparse_categorical_crossentropy
    optimizer:
      type: Adam
      lr: 0.00001
    dropout: 0.1
    layers:
      - conv1d:
          filters: 64
          kernel_size: 16
          use_batchnorm: True
      - conv1d:
          filters: 64
          kernel_size: 5
          use_batchnorm: True
      - conv1d:
          filters: 32
          kernel_size: 2
          use_batchnorm: True
      - flatten
      - fc:
          nodes: 512
      - fc:
          nodes: 512
      - embedding:
          nodes: 64
      - output
    callbacks:
      tensorboard:
        log_dir: .tensorboard_logs
        write_images: True
      # lr_scheduler:
      #   cutoff_epoch: 25
      #   decay: exponential
      csv_logger:
        dir: training_logs
      checkpoint:
        dir: model_checkpoints
