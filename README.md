# MicrocontrollerRecognizer
My thesis concerns deploying a *tiny* text-independent speaker verification model onto an edge device, specifically the [Arduino Nano 33 BLE](https://store.arduino.cc/usa/nano-33-ble). ![Arduino-Device](./thesis-paper/assets/section4/arduino_nano_ble_sense.jpg)

The models are trained using log-mel spectrograms, generated by [librosa](https://librosa.org/doc/latest/generated/librosa.feature.melspectrogram.html), from a `tf.Dataset` over the [LibriSpeech](http://www.openslr.org/12/), [VoxCeleb1](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/), and [CommonVoice](https://commonvoice.mozilla.org/en/datasets) datasets. They were then validated on the `test-*` datasets in `LibriSpeech` and all of [VCTK](https://datashare.is.ed.ac.uk/handle/10283/3443). Here, we've trained the models using `tensorflow` v2.3.

The models are then deployed onto our Arduino device using the code in [`MicrocontrollerRecognizer`](./MicrocontrollerRecognizer).

## Models
In training, the models final layer is a custom defined `SpeakerSimilarityMatrixLayer`, 
```python
class SpeakerSimilarityMatrixLayer(tf.keras.layers.Layer):

    def __init__(self, n_speakers, utterances_per_speaker, embedding_length):
        super(SpeakerSimilarityMatrixLayer, self).__init__()
        self.W = tf.Variable(name='W', trainable=True, initial_value=10.)
        self.b = tf.Variable(name='b', trainable=True, initial_value=-5.)
        self.N = n_speakers
        self.M = utterances_per_speaker
        self.P = embedding_length

    def call(self, inputs):
        """
        Args:
            inputs: output from the final Dense(self.P) embedding layer, representing each
                    speakers "voiceprint" for a given utterance.
        Returns:
            An [NM x N] cosine similarity matrix comparing the NM utterances in each column
            to the N centroids (representing the averaged embedding for a given speaker).
        """
        # [n_speakers x utterances x embedding_length]
        inputs = tf.math.l2_normalize(inputs, axis=1)
        utterance_embeddings = tf.reshape(inputs, shape=[self.N, self.M, self.P])

        # the averaged embeddings for each speaker: [n_speakers x embedding_length]
        centroids = tf.math.l2_normalize(
            tf.reduce_mean(utterance_embeddings, axis=1),
            axis=1
        )
        # now we need every utterance_embedding's cosine similarity with those centroids
        # returning: [n_speakers * utterances x n_speakers (or n_centroids)]
        S = tf.concat(
            [tf.matmul(utterance_embeddings[i], centroids, transpose_b=True) for i in range(self.N)],
            axis=0
        )
        return tf.abs(self.W) * S + self.b
```
which is responsible for taking all the embedding vectors which are outputs of the upstream `Dense` layer 
and generating an $[NM,N]$ cosine similarity matrix over which the loss is computed. This approach is motivated
by Wan, Wang, Papir, and Lopez-Moreno (2017) [Generalized End-to-End Loss](https://arxiv.org/abs/1710.10467). Once 
the model is trained, a speaker is _enrolled_ by taking the average of several (up to you) embedding vectors, which are 
the `Dense` layer right before our `SpeakerSimilarityMatrixLayer`, representing utterances which belong to them. 

Trained, frozen models can be found in [`tensorflow/frozen_models`](./tensorflow/frozen_models). The 4 sub-directories contain:

| Subdirectory | Contents                                     |
| :----------- | :--------------------------------------------|
| `confs`      | Configs for each serialized model's training |
| `embedding`  | Models which output an utterance's embedding |
| `full`       | Models which output the `SpeakerSimilarityMatrixLayer` output|
| `tiny`       | TensorflowLite Micro models | 

## Deployment
Deploying the models as `TensorflowLite` objects onto Arduino requires us to essentially re-implement the feature engineering
steps which `librosa` provides in `C/C++`. The code used to test that part of the project is contained in [`cpp`](./cpp). Ultimately,
it is then integrated into the Arduino program contained in [`MicrocontrollerRecognizer`](./MicrocontrollerRecognizer).